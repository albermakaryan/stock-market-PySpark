{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26eced0-23e1-40f9-b9ec-70d28afe0191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from sparknlp.annotator import LemmatizerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a589db8c-f2df-423d-b94c-35221f4a7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+\n",
      "|      published date|             article|sentiment_score|\n",
      "+--------------------+--------------------+---------------+\n",
      "|Fri, 17 Dec 2021 ...|3.53 -13%\\n\\n3.54...|            0.0|\n",
      "|Tue, 03 Jan 2017 ...|3.12 -12%\\n\\n3.13...|            0.0|\n",
      "|Tue, 03 Jan 2017 ...|3.12 -12%\\n\\n3.13...|            0.0|\n",
      "|Thu, 05 Sep 2019 ...|6.69 -8%\\n\\n6.72 ...|            0.0|\n",
      "|Tue, 08 Jan 2019 ...|11.6 -7%\\n\\n11.8 ...|            0.0|\n",
      "|Wed, 10 Apr 2024 ...|The best graphics...|            0.0|\n",
      "|Wed, 19 Sep 2018 ...|TweakTown's Ratin...|            0.0|\n",
      "|Wed, 19 Sep 2018 ...|TweakTown's Ratin...|            0.0|\n",
      "|Fri, 02 Jun 2023 ...|This transcript w...|            0.0|\n",
      "|Thu, 16 Nov 2023 ...|Every day, cloud-...|            0.0|\n",
      "|Wed, 05 Apr 2023 ...|MLCommons today r...|            0.0|\n",
      "|Wed, 29 Jun 2022 ...|MLCommonsâ€™ latest...|            0.0|\n",
      "|Tue, 13 Jun 2017 ...|One area that is ...|            0.0|\n",
      "|Fri, 05 Apr 2024 ...|We can happily re...|            0.0|\n",
      "|Wed, 21 Aug 2019 ...|The first of Metr...|            0.0|\n",
      "|Wed, 21 Aug 2019 ...|The first of Metr...|            0.0|\n",
      "|Wed, 15 Apr 2020 ...|Introduction\\n\\nI...|            0.0|\n",
      "|Wed, 15 Apr 2020 ...|Introduction\\n\\nI...|            0.0|\n",
      "|Fri, 30 Apr 2021 ...|Four years ago, w...|            0.0|\n",
      "|Fri, 30 Apr 2021 ...|Four years ago, w...|            0.0|\n",
      "+--------------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sentiment Analysis with PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(\"I love this product\",),\n",
    "        (\"This is terrible\",),\n",
    "        (\"It's okay\",)]\n",
    "\n",
    "\n",
    "df = spark.read.option(\"header\",\"true\").json(\"../data/json/NVIDIA/\")\n",
    "df = df.select(\"published date\",\"article\")\n",
    "\n",
    "# Create Spark DataFrame\n",
    "# df = spark.createDataFrame(data, [\"text\"])\n",
    "\n",
    "# Define a function to calculate sentiment score\n",
    "def calculate_sentiment(text):\n",
    "    # Define positive and negative words\n",
    "    # positive_words = [\"love\", \"great\", \"awesome\", \"excellent\"]\n",
    "    positive_words = [\n",
    "    \"Love\", \"Happy\", \"Joy\", \"Excited\", \"Wonderful\", \"Amazing\", \"Fantastic\", \"Great\", \"Excellent\", \"Awesome\",\n",
    "    \"Delight\", \"Bliss\", \"Grateful\", \"Hopeful\", \"Peaceful\", \"Success\", \"Thrilled\", \"Enthusiastic\", \"Optimistic\",\n",
    "    \"Admire\", \"Brilliant\", \"Cheerful\", \"Ecstatic\", \"Energetic\", \"Fascinating\", \"Glorious\", \"Harmony\", \"Inspirational\",\n",
    "    \"Magical\", \"Miracle\", \"Radiant\", \"Sensational\", \"Triumphant\", \"Vibrant\", \"Wholesome\", \"Affection\", \"Blessing\",\n",
    "    \"Caring\", \"Charming\", \"Courage\", \"Dazzling\", \"Dream\", \"Empower\", \"Freedom\", \"Glowing\", \"Healing\", \"Honor\",\n",
    "    \"Incredible\", \"Jubilant\", \"Kindness\", \"Liberate\", \"Marvelous\", \"Noble\", \"Paradise\", \"Rejoice\", \"Spectacular\",\n",
    "    \"Sunny\", \"Transform\", \"Uplift\", \"Wondrous\", \"Abundant\", \"Blissful\", \"Calm\", \"Divine\", \"Euphoric\", \"Genuine\",\n",
    "    \"Heartfelt\", \"Inspire\", \"Majestic\", \"Nurture\", \"Overflowing\", \"Radiate\", \"Serene\", \"Sparkling\", \"Tranquil\",\n",
    "    \"Unconditional\", \"Vitality\", \"Warmth\", \"Zest\", \"Adoration\", \"Bountiful\", \"Celebrate\", \"Compassion\", \"Elegant\",\n",
    "    \"Faith\", \"Gratitude\", \"Hope\", \"Imagination\", \"Lively\", \"Miraculous\", \"Passion\", \"Renew\", \"Serenity\", \"Splendid\",\n",
    "    \"Treasure\", \"Vibrant\", \"Wisdom\"]\n",
    "\n",
    "    negative_words = [\n",
    "    \"Hate\", \"Sad\", \"Angry\", \"Disappointed\", \"Terrible\", \"Horrible\", \"Awful\", \"Disgusting\", \"Annoyed\", \"Frustrated\",\n",
    "    \"Depressed\", \"Gloomy\", \"Miserable\", \"Dreadful\", \"Unhappy\", \"Painful\", \"Sorrow\", \"Regret\", \"Agony\", \"Grief\",\n",
    "    \"Melancholy\", \"Despair\", \"Hopeless\", \"Lonely\", \"Heartbroken\", \"Wretched\", \"Suffering\", \"Apathetic\", \"Desperate\",\n",
    "    \"Furious\", \"Enraged\", \"Bitter\", \"Jealous\", \"Hostile\", \"Offensive\", \"Resentful\", \"Pessimistic\", \"Gloomy\",\n",
    "    \"Nauseating\", \"Repulsive\", \"Disappointing\", \"Disgusted\", \"Disheartened\", \"Disillusioned\", \"Dismal\", \"Distressed\",\n",
    "    \"Disturbed\", \"Grieving\", \"Lament\", \"Languish\", \"Moody\", \"Morose\", \"Nervous\", \"Pessimism\", \"Rage\", \"Rueful\",\n",
    "    \"Shameful\", \"Somber\", \"Sorrowful\", \"Stressful\", \"Tearful\", \"Tragic\", \"Troubled\", \"Unpleasant\", \"Upset\", \"Vexed\",\n",
    "    \"Weary\", \"Woeful\", \"Worst\", \"Worried\", \"Abominable\", \"Abysmal\", \"Anguish\", \"Anxious\", \"Appalled\", \"Atrocious\",\n",
    "    \"Dejected\", \"Detest\", \"Dismayed\", \"Dread\", \"Fretful\", \"Grumpy\", \"Horrified\", \"Humiliated\", \"Inferior\", \"Insecure\",\n",
    "    \"Irked\", \"Lousy\", \"Mournful\", \"Nasty\", \"Panicked\", \"Pathetic\", \"Perplexed\", \"Repugnant\", \"Shocked\", \"Stressed\",\n",
    "    \"Tense\", \"Tiresome\", \"Unbearable\", \"Uncertain\", \"Unhappy\", \"Unpleasant\", \"Unsettled\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    \n",
    "    # Count positive and negative words in the text\n",
    "    num_positive = sum(1 for word in text.split() if word.lower() in positive_words)\n",
    "    num_negative = sum(1 for word in text.split() if word.lower() in negative_words)\n",
    "    \n",
    "    # Calculate sentiment score (positive words - negative words)\n",
    "    sentiment_score = (num_positive - num_negative) / max(num_positive + num_negative, 1)\n",
    "    \n",
    "    return sentiment_score\n",
    "\n",
    "# Define a UDF to apply sentiment analysis to Spark DataFrame\n",
    "sentiment_udf = udf(calculate_sentiment, FloatType())\n",
    "\n",
    "# Apply sentiment analysis to DataFrame\n",
    "df = df.withColumn(\"sentiment_score\", sentiment_udf(df[\"article\"]))\n",
    "\n",
    "# Show results\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77de13c9-9b8c-49f4-acb6-9f1fa2b2c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:708)\n",
      "\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:752)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:675)\n",
      "\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:641)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:617)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:574)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:532)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4e738e-fbde-484d-9bb3-bb3d16bfd719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6af570-64d2-46db-92dd-dd120d79da1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_project_kernel",
   "language": "python",
   "name": "big_data_project_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
